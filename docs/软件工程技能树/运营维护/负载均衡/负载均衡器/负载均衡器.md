---
title: 负载均衡器
slug: 负载均衡器
sidebar_position: 1
---


# 负载均衡器

Author：NA

因为潮业务手搓的一个负载均衡器，主要包括了nginx日志监控、perf监控、负载均衡等功能。

进行了一些简单的压测，工具和过程也放在里面。

repo：

follow me from：

https://t.me/+5IH64rSM3AVmN2M1

# Developing in `golang`

Some tricky topics involved:

- Multithread and stubborn queue control.
- Build a stubborn performance test and `goroutine` leak test.
- Why you should close file description in each channel.

## Building a go program with RESTful template

Reusable code:

- RESTful router.
- Definition and Handler of object.

more.

You may want to define and expose RESTful apis along with the definition of objects. And build the template of project.

## The main part of a proxy

Code.

Tricky:

- Be sure to Close each side when the other side sends EOF.
    - Achieve with defer.
    - Never Close unopened connection.

- &lt;aside&gt; 👉 Set defer to close right after establishing. Be careful with “Closing not opened.”
- &lt;/aside&gt;
- Recycle resources.
    - No forever hang connection and `goroutine` leak: Closing each side and timeout.
    - No global variable creation. All local variables are released to ensure no memory leak.

- Display readable error message when fault occurs.

# Random and Hash

Topic about load balancing? Which is better?

Random

`Intn()` and `rand()` % ? Why “Not equal possibility”?

## Hash

Rand and Hash.

- Rand mechanism. Possibility distribution.
- Easy hash is `mod`. Length may affect performance. Sparse would cause waste.
    - Sparse cost for hash?

- Weighted distribution.

# Prometheus Metrics

To enable monitoring, I need to expose this as prometheus metrics.

# Automatic basic test

How do you compose a automatic tester? Not just inside golang itself. You may want to build a integrated test and run by itself.

# Promotion to be a c10k

# Build test

- Memory use. Channel use.
- Response time.
- Overloading performance.

# Perfing Golang

[[golang]7种 Go 程序性能分析方法](https://www.cnblogs.com/landv/p/11274877.html)

Go Executable runs in many layers of environments:

- Operating system: OS.
- go runtime.

With these, you can glean some useful statistics:

- Time: /usr/bin/time
- fd: File descriptor
- IO and net work.
- GC behavior.
- Memory.
- CPU time hotspot.

How do you gather these statistics?

⇒ Build a generic perf render.

## Naive performance test

To avoid networking bottleneck, test local io loopback bandwidth with `iperf`

```go
iperf3 -s 15999
iperf3 -c 127.0.0.1 15999
```

Watch the traffic on network interface with `iftop`

```go
sudo iftop -i lo -nN
```

Get performance.

Easily get:

- `iftop` has shown exact band rate with `iperf3`.
- With huge `io` , CPU cores are busy with sending packages. The bottleneck for `lo` is cpu now. 😅 …ok.

想想在一台虚拟机上自己对自己压测有点蠢，更换两台物理机测试😦

## Perfing

预测试：

- 不经过代理服务器。
- 左侧为srv2，包含待测服务；
- 右侧为srv1，为压测机，含有测试程序ab、受测代理的访问目标nginx。

符合预期，机器是由百兆交换机连接的。

To take a glimpse at the performance, `ab` from apache-utils comes in handy.

```go
sudo apt-get install apache2-utils
```

[ab - Apache HTTP server benchmarking tool](https://httpd.apache.org/docs/2.4/programs/ab.html)

For io pressure is considered dangerous for linux, some mechanism would limit the rate. Some options to be tuned:

- ulimit 20000
- net.ipv4.tcp_syncookies = 0

嗯，最后像模像样地跑了个测试，发现负载完全不在io上，在cpu上（

### 测试:

- 环境同上。从略

```bash
sudo ab -c 1000 -n 10000 -H "ip.zjuqsc.com" -H "X-Egress-Scheme: http" \\
        -H "X-Egress-Host: 172.20.216.100:80" -r <http://10.76.8.19:18999/>
```

静置机器：

运行到中段稳定状态：

测试结束：

- 负载情况：
    - 业务机cpu跑满。暂时未知为啥这么吃U；
    - 测试机和业务机之间的io没有满，不是瓶颈；
    - 测试机本身的core没有跑满，瓶颈不在nginx终端服务上。

- 资源消耗：
    - 看了一下业务的memory消耗，一开始是450M左右，跑到中段是685M，最后是772M。其中经历了15万次请求。之后计算平均每请求和应有的差异，以确证memoryleak；过了十几分钟又下来了一些，看上去是因为gc慢慢下来了…
    - 至少存活了…

- Dump 日志进行分析：
    - json 全序列化的大小只有16MB，这么看来显然memoryleak了（

# Monitor and Debug

Use golang `runtime` to inspect usage and goroutine leak for golang.

- Memory allocation and GC.
- Goroutine statistics.
- File descriptor.

## System side

```bash
# system
sudo systemctl status ipmanager.service
```

暂时地观察fd，可以用：

```bash
sudo lsof -a -p <PID>
```

可用于检查连接是否被正常关闭。

## Runtime perf

runtime provides:

To Enable

```bash
# pprof 
(go tool )pprof -http=:9099 <http://10.76.8.19:9091/debug/pprof>
```

## CoreDump

To enable core dump, set limit:

```bash
ulimit -a # system limitation of system resources.
ulimit -S -c unlimited #
ulimit -S -c 1073741824 # 1G (by default in B)
```

To trigger coredump manually:

```bash
kill -s SIGSEGV <PID>
```

&lt;aside&gt; 👉 Note: `Systemctl` service produced no coredump by default. Rather than `ulimit`, `LimitCORE` needs to be set. Refer to:

&lt;/aside&gt;

[systemd.exec](https://www.freedesktop.org/software/systemd/man/systemd.exec.html#Process%20Properties)

Or, you can produce coredump with gdb:

```bash
sudo gdb -p <pid>
gcore
```

Download from origin: (1G).

- Including different `.so` files…

# Debug

&lt;aside&gt; 👉 You can’t use a blocking function in goroutine if you can’t guarantee it’s safe… You can’t break goroutine from outside, and you can’t use signal to stop the blocking function. You can only rewrite them.

&lt;/aside&gt;

The `io` package has provided primitives of `io`, hiding the complexity of tcp protocol. You are actually reading from and writing to a stream.

But from this, you are limited to its implementation without timeout. Custom `CopyWithTimeout` needs to be implemented.

## `io`: Streaming Reader

Golang provides `io` as the primitives managing reading and writing. The object implementing these interfaces may comes from different systems.

There are several featured functions:

### `io.Copy()`

Try to call `ReadFrom` and `WriteTo()`

If none, try to allocate a buffer and use for copying.

Promotion:

- `io.CopyWithBuffer`: Use provided buffer.
- Use `bufio` for buffered `io` reading and writing. More featured methods and much more efficient for small `io`reading.

Drawbacks:

- Blocking. No interrupt allowed. So you can’t use it with clock.

# TCP Proxy: From byte to byte

---

[Go经典阻塞式TCP协议流解析的实践](https://mp.weixin.qq.com/s/NG3f-KkjtJBTVdRHQKLXOg)

# AB Test with `nginx`

`nginx` split client.

```go
split_clients "${remote_addr}AAA" $variant {
               0.5%               .one;
               2.0%               .two;
               *                  "";
}
```

Used for A/B Testing. Tracing log to show split? (Add header and Log.)

## TODOS

More flexible IP log fetching.

- Streaming huge json objects. (Over 16M).

Refer to benthos source code for overview of streaming:

[https://github.com/benthosdev/benthos](https://github.com/benthosdev/benthos)

Debug under pressure.

- Analyze core-dump !!!
- Analyze with go perfing !!!

Inspect and track from systemctl.

- More precise usage?

# 踩坑记录

Channel and goroutine

```go
func Proxy(src net.Conn){
        var d string
        if config.C.Debug {
                // TODO: Configurable load balancing: Marking upstream and set upstream by hand.
                d = "127.0.0.1:19106"
        } else {
                d = LoadBalance()
        }

        dst, err := net.DialTimeout("tcp", d, time.Duration(config.C.DialTimeOut)*time.Second)

        if err != nil {
                fmt.Println("dial failure to service detected: " + err.Error())
                // TODO Send back timeout info.
                src.Write([]byte("HTTP/1.1 502 Bad Gateway\\n\\r[PROXY RESENDING ERROR FROM UPSTREAM:]\\n\\r" + err.Error() + "\\n"))
                src.Close()
                return
        }

        if Gate(src) != nil {
                fmt.Println("Gate.")
                return
        }

        done := make(chan struct{})
        // To make a duplex channel, you may need two goroutines.
        // Copy is streaming. It returns when EOF reaches.

        defer func() {
                dst.Close()
                src.Close()
        }()

        go func() {
                io.Copy(dst, src)
                done <- struct{}{}
        }()
        go func() {
                io.Copy(src, dst)
                done <- struct{}{}
        }()

        select {
        case <-done:
                return
        case <-time.After(time.Duration(config.C.MaxConnectionTimeout) * time.Second):
                fmt.Println("Connection timeout.")
                src.Write([]byte(TimeOut))
                dst.Write([]byte(TimeOut))
        }
        // Either side connection close would cause "defer: Send EOF and close connection."
}
```

&lt;aside&gt; 👉 This is problematic code, causing memory leak. Can you see what’s the problem?

&lt;/aside&gt;

Goroutine probe:

…Oh.. `proxy()` Not released…

These two points where memory leaks:

```bash
go func() {
                io.Copy(*dst, *src)
                done <- struct{}{}
}()
go func() {
                io.Copy(*src, *dst)
                done <- struct{}{}
}()
```

One `goroutine` exited but another didn’t.

I thought:

> When `dst` sends it data and EOF, the last `goroutine` would exit and send through “done” channel to main thread. But the another side just close the connection but not sending back EOF. That’s causing `io.Copy()`blocking.

But file descriptor closed, can’t that cause `io.Copy` returning?

That’s not true. For:

- Goroutine can’t be interrupt outside. That means we can’t set a timeout and break the blocked `io.Copy`. If file descriptor closing can’t lead to `io.Copy` to return, that’s making it a leaked goroutine, just like here. Designer can’t be making things so stupid.
- Besides EOF reaches, errors happening could also cause `io.Copy` to return. As doc mentioned it.

&lt;aside&gt; 👉 Just… Read documentation with care…

&lt;/aside&gt;

So what’s happening here?

This is a working solution:

```bash
defer func() {
                (*dst).Close()
                (*src).Close()
        }()

        go func() {
                if _, err := io.Copy(*dst, *src); err != nil {
                        return
                }
                done <- struct{}{}
        }()
        go func() {
                if _, err := io.Copy(*src, *dst); err != nil {
                        return
                }
                done <- struct{}{}
        }()

        select {
        case <-done:
                return
        case <-time.After(p.timeOut):
                //fmt.Println("Connection timeout.")
                (*src).Write([]byte(p.timeOutErr.Error()))
                (*dst).Write([]byte(p.timeOutErr.Error()))
                return
        }
```

TODO: What’s the precise behavior of channel?

TODO: more about golang GC.

